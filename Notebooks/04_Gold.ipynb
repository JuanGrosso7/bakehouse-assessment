{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b13ec498-38af-4252-add9-06de738c5370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Notebook: 04_Gold.ipynb\n",
    "# Sets up Gold layer using DLT, creating two tables:\n",
    "# 1. \"transactions_per_product\" \n",
    "# 2. \"transactions_details\" \n",
    "\n",
    "import dlt\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c316117d-038d-4eb6-b3aa-e0b0a59a4f2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Table: transactions_per_product\n",
    "\n",
    "@dlt.table(comment=\"Pivoted transactions per product aggregated by total sales per day\")\n",
    "def transactions_per_product():\n",
    "    # Read the transactions table from the Silver layer.\n",
    "    df = spark.table(\"jp_assessment.latam_lab_silver.sales_transactions\")\n",
    "    # Convert the transaction timestamp to a date for grouping.\n",
    "    df = df.withColumn(\"trans_date\", F.to_date(\"dateTime\"))\n",
    "    # Pivot the data: for each day, sum the totalPrice per product.\n",
    "    df_pivot = df.groupBy(\"trans_date\").pivot(\"product\").agg(F.sum(\"totalPrice\").alias(\"total_sales\"))\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "040b3313-3711-4d82-81aa-6f5823b76d47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Table: transactions_details\n",
    "\n",
    "@dlt.table(comment=\"Detailed transactions enriched with customer information\")\n",
    "def transactions_details():\n",
    "    # Read transactions and customer data from the Silver layer.\n",
    "    df_trans = spark.table(\"jp_assessment.latam_lab_silver.sales_transactions\")\n",
    "    df_customers = spark.table(\"jp_assessment.latam_lab_silver.sales_customers\")\n",
    "    # Join transactions with customers on customerID to add customer name, address, and email.\n",
    "    df_details = df_trans.join(df_customers, \"customerID\", \"left\") \\\n",
    "                  .select(\n",
    "                      \"transactionID\",\n",
    "                      \"customerID\",\n",
    "                      \"dateTime\",\n",
    "                      \"product\",\n",
    "                      \"quantity\",\n",
    "                      \"totalPrice\",\n",
    "                      \"paymentMethod\",\n",
    "                      F.concat_ws(\" \", F.col(\"first_name\"), F.col(\"last_name\")).alias(\"customer_name\"),\n",
    "                      \"address\",\n",
    "                      \"email_address\"\n",
    "                  )\n",
    "    return df_details"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
